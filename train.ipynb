{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Experiment 1**\n",
        "\n",
        "En aquest notebook es realitza l'entrenament d'un model YOLO (versió 8) per a la base de dades original de fruites sintètiques. Inclou la configuració inicial, el carregament i preprocessament de les dades, l'entrenament i l'avaluació del rendiment del model amb diverses mètriques."
      ],
      "metadata": {
        "id": "2zxPoMfP_prY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LZYeDbgs5Kit"
      },
      "outputs": [],
      "source": [
        "# GPU's information\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install the ultralytics package\n",
        "!pip install ultralytics"
      ],
      "metadata": {
        "id": "u0z9A6uN5OZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import the necessary libraries\n",
        "from ultralytics import YOLO\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display, Image\n",
        "from IPython import display\n",
        "display.clear_output()\n",
        "!yolo mode= yolo checks"
      ],
      "metadata": {
        "id": "3W41QpGk5Ocs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Import the dataset from Roboflow\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"api_key\")\n",
        "project = rf.workspace(\"fruitesd\").project(\"fd-ndbok\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"yolov8\")"
      ],
      "metadata": {
        "id": "hagrhXpR5Oey"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import subprocess\n",
        "\n",
        "# Define the epochs and batch size combinations\n",
        "epochs_list = [50, 100, 150]\n",
        "batch_sizes = [4, 16, 32]\n",
        "patience_dict = {50: 10, 100: 15, 150: 20}\n",
        "\n",
        "# Path to the data's configuration file\n",
        "data_file = '/content/FD-1/data.yaml'\n",
        "model_file = 'yolov8m.pt'\n",
        "\n",
        "# Base directory to save the results\n",
        "base_results_dir = '/content/training_result'\n",
        "os.makedirs(base_results_dir, exist_ok=True)\n",
        "\n",
        "# Train with each combination of epochs and batch size\n",
        "for epochs in epochs_list:\n",
        "    for batch_size in batch_sizes:\n",
        "        run_name = f'epochs_{epochs}_batch_{batch_size}'\n",
        "        patience = patience_dict[epochs]\n",
        "\n",
        "        command = [\n",
        "            'yolo', 'task=detect', 'mode=train',\n",
        "            f'model={model_file}',\n",
        "            f'data={data_file}',\n",
        "            f'epochs={epochs}',\n",
        "            'imgsz=640',\n",
        "            f'batch={batch_size}',\n",
        "            f'patience={patience}',\n",
        "            f'name={run_name}',\n",
        "            f'project={base_results_dir}'\n",
        "        ]\n",
        "\n",
        "        # Execute the training command\n",
        "        subprocess.run(command)\n",
        "\n",
        "        print(f'Entrenament completat per {epochs} epochs i batch size {batch_size}')\n",
        "\n",
        "        # Validation\n",
        "        command_val = [\n",
        "            'yolo', 'task=detect', 'mode=val',\n",
        "            f'model={os.path.join(base_results_dir, run_name, \"weights/best.pt\")}',  #path to the trained model\n",
        "            f'data={data_file}',\n",
        "            'imgsz=640',\n",
        "            f'project={base_results_dir}',\n",
        "            f'name={run_name}_val'\n",
        "        ]\n",
        "        subprocess.run(command_val)\n",
        "\n",
        "        print(f'Validació completada per {epochs} epochs i batch size {batch_size}')\n"
      ],
      "metadata": {
        "id": "7RxeB4tT5Ohs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To save the results for future uses\n",
        "import shutil\n",
        "# Compress the folder of base_results_dir in a ZIP file\n",
        "shutil.make_archive('/content/trs', 'zip', '/content/training_result')"
      ],
      "metadata": {
        "id": "32bOAKDobupE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Copy the ZIP file in Google Drive\n",
        "!cp /content/trs.zip /content/drive/MyDrive/tr.zip"
      ],
      "metadata": {
        "id": "ORUyP72DxMNQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Path to the results folder\n",
        "results_base_dir = '/content/training_result'\n",
        "\n",
        "# Initialization of the different combinations of epochs and batch sizes\n",
        "combinations = [(50, 4), (50, 16), (50, 32), (100, 4), (100, 16), (100, 32), (150, 4), (150, 16), (150, 32)]\n",
        "\n",
        "# Initialize the data\n",
        "epochs_data = []\n",
        "batch_data = []\n",
        "map50_95_data = []\n",
        "precision_data = []\n",
        "recall_data = []\n",
        "train_box_loss_data = []\n",
        "train_cls_loss_data = []\n",
        "val_box_loss_data = []\n",
        "val_cls_loss_data = []\n",
        "\n",
        "# Read the results of each training\n",
        "for epochs, batch_size in combinations:\n",
        "    run_name = f'epochs_{epochs}_batch_{batch_size}'\n",
        "    results_file = os.path.join(results_base_dir, run_name, 'results.csv')\n",
        "\n",
        "    # Check if the results file exists\n",
        "    if os.path.exists(results_file):\n",
        "        results = pd.read_csv(results_file)\n",
        "\n",
        "        # Clean the column names\n",
        "        results.columns = results.columns.str.strip()\n",
        "\n",
        "        # Use the columns to obtain the metrics\n",
        "        try:\n",
        "            map50_95 = results['metrics/mAP50-95(B)'].iloc[-1]\n",
        "            precision = results['metrics/precision(B)'].iloc[-1]\n",
        "            recall = results['metrics/recall(B)'].iloc[-1]\n",
        "            train_box_loss = results['train/box_loss'].iloc[-1]\n",
        "            train_cls_loss = results['train/cls_loss'].iloc[-1]\n",
        "            val_box_loss = results['val/box_loss'].iloc[-1]\n",
        "            val_cls_loss = results['val/cls_loss'].iloc[-1]\n",
        "        except KeyError as e:\n",
        "            print(f'The column {e} does not exist in {results_file}')\n",
        "            continue\n",
        "\n",
        "        epochs_data.append(epochs)\n",
        "        batch_data.append(batch_size)\n",
        "        map50_95_data.append(map50_95)\n",
        "        precision_data.append(precision)\n",
        "        recall_data.append(recall)\n",
        "        train_box_loss_data.append(train_box_loss)\n",
        "        train_cls_loss_data.append(train_cls_loss)\n",
        "        val_box_loss_data.append(val_box_loss)\n",
        "        val_cls_loss_data.append(val_cls_loss)\n",
        "    else:\n",
        "        print(f'The file {results_file} does not exist')\n",
        "\n",
        "# Create separate plots for each batch size\n",
        "batch_sizes = set(batch_data)\n",
        "\n",
        "for batch_size in batch_sizes:\n",
        "    fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
        "\n",
        "    # Plot Train and Validation Loss for current batch size\n",
        "    batch_indices = [i for i, b in enumerate(batch_data) if b == batch_size]\n",
        "    batch_epochs = [epochs_data[i] for i in batch_indices]\n",
        "    batch_train_box_loss = [train_box_loss_data[i] for i in batch_indices]\n",
        "    batch_val_box_loss = [val_box_loss_data[i] for i in batch_indices]\n",
        "    batch_train_cls_loss = [train_cls_loss_data[i] for i in batch_indices]\n",
        "    batch_val_cls_loss = [val_cls_loss_data[i] for i in batch_indices]\n",
        "\n",
        "    ax.plot(batch_epochs, batch_train_box_loss, label=f'Train Box Loss Batch Size {batch_size}')\n",
        "    ax.plot(batch_epochs, batch_val_box_loss, label=f'Val Box Loss Batch Size {batch_size}', linestyle='--')\n",
        "    ax.plot(batch_epochs, batch_train_cls_loss, label=f'Train Cls Loss Batch Size {batch_size}', linestyle='-.')\n",
        "    ax.plot(batch_epochs, batch_val_cls_loss, label=f'Val Cls Loss Batch Size {batch_size}', linestyle=':')\n",
        "    ax.set_xlabel('Epochs')\n",
        "    ax.set_ylabel('Loss')\n",
        "    ax.set_title(f'Train and Validation Loss vs Epochs for Batch Size {batch_size}')\n",
        "    ax.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Create combined plots\n",
        "fig, ax = plt.subplots(2, 1, figsize=(10, 15))\n",
        "\n",
        "# Plot mAP50-95\n",
        "for batch_size in set(batch_data):\n",
        "    batch_indices = [i for i, b in enumerate(batch_data) if b == batch_size]\n",
        "    batch_epochs = [epochs_data[i] for i in batch_indices]\n",
        "    batch_map50_95 = [map50_95_data[i] for i in batch_indices]\n",
        "\n",
        "    ax[0].plot(batch_epochs, batch_map50_95, label=f'Batch Size {batch_size}')\n",
        "\n",
        "ax[0].set_xlabel('Epochs')\n",
        "ax[0].set_ylabel('mAP50-95')\n",
        "ax[0].set_title('mAP50-95 vs Epochs for Different Batch Sizes')\n",
        "ax[0].legend()\n",
        "\n",
        "# Plot precision and recall\n",
        "for batch_size in set(batch_data):\n",
        "    batch_indices = [i for i, b in enumerate(batch_data) if b == batch_size]\n",
        "    batch_epochs = [epochs_data[i] for i in batch_indices]\n",
        "    batch_precision = [precision_data[i] for i in batch_indices]\n",
        "    batch_recall = [recall_data[i] for i in batch_indices]\n",
        "\n",
        "    ax[1].plot(batch_epochs, batch_precision, label=f'Precision Batch Size {batch_size}')\n",
        "    ax[1].plot(batch_epochs, batch_recall, label=f'Recall Batch Size {batch_size}', linestyle='--')\n",
        "\n",
        "ax[1].set_xlabel('Epochs')\n",
        "ax[1].set_ylabel('Precision/Recall')\n",
        "ax[1].set_title('Precision and Recall vs Epochs for Different Batch Sizes')\n",
        "ax[1].legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "wiXMnvkLbpSk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}